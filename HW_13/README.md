# Homework 13

## Пункты 1 и 2 в этом ДЗ как пункты 4 и 5 из предыдущей ДЗ. Там они уже описаны

## 3. Установить JMeter и написать тестовый сценарий для проверки производительности приложения путем выполнения HTTP GET запроса http://<NGINX_IP>:<NGINX_PORT>/ping от 100 пользователей

![task3](screenshots/task3.png)

![task3_1](screenshots/task3_1.png)

```txt
Latency на первых прогонах была в районе 1035 мс
Чем больше итераций запросов проходило, тем медленее становился отклик сервера
На последних итерациях latency была в районе 9147 мс
Сервер выдержал нагрузку в 100 юзеров
```

**Первый запрос**
![task3_2](screenshots/task3_2.png)

**Последний запрос**
![task3_3](screenshots/task3_3.png)

## 4. Запустить ещё один экземпляр Python REST Api приложения на другом порту

```bash
cd ~/lecture15/api
python3 main.py 5001
```

## 5. Изменить конфигурацию Nginx, чтобы он использовал в качестве бэкенда 2 приложения

```txt
Для использования nginx в качестве бэка 2 приложения используется функция upstream
```

![task5](screenshots/task5.png)

## 6. Повторить JMeter сценарий и сравнить результаты

```txt
Прогнав нагрузочный тест в 100 пользователей на 2 приложениях можно сделать вывод, что нагрузка распределяется пополам между ними
Первый запрос составил около 1000 мс
Последний запрос составил около 4215 мс

Так же подсчитав запросы получилось, что из 100 штук - 52 пришлось на 1 приложения на порте 5000, а 48 на второе на порте 5001
```

**Первый запрос**
![task6](screenshots/task6.png)

**Последний запрос**
![task6_1](screenshots/task6_1.png)
